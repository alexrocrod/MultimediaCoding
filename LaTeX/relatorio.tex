\documentclass[a4paper, 11pt]{article}
\usepackage{geometry}
\usepackage{indentfirst}
\usepackage{setspace}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{caption}
\usepackage{indentfirst}
\setlength{\parindent}{20pt}
\usepackage{amssymb}
\usepackage{float}

\graphicspath{ {./images/} }
\geometry{left=2.5cm, right=2.5cm, top=2.5cm, bottom=2.5cm}

\begin{document}	
	\title{Project \# 3. Multimedia Coding }
	\author{{\small Alexandre Rodrigues (2039952)}}
	\date{\today}
	\maketitle
	
	\section{Introduction}
		This reports is dedicated to explain the usage of the LBG-split algorithm and how to implement it.
		The Linde-Buzo-Gray algorithm is a lossy coding technique, it uses vector quantization, meaning that a block of input samples (size L) is processed together.
		$\ldots$
	
	\section{Technical Approach}
		Each vector of size L samples can be defined as
		\begin{equation}
			x = [x_1, x_2, \ldots, x_L], x \in R^L
		\end{equation}
		where $x_i, i=1,2,\ldots,L$ are input samples. 
		Using $y_i $ as a codevector, 
		\begin{equation}
			B =  \{y_1, y_2, \ldots, y_L\}
		\end{equation} 
		is the set of reconstruction levels, i.e. the codebook, of size K.
		The decision cells will be
		\begin{equation}
			I_i \in R^L, i = 1, 2, \ldots, K, such that I_i intersect I_j = 0 \aleph i \neq j and union k i=1 I_i = R^L
		\end{equation} 
	
		\subsection{LBG}
			Since we do not know the probablity distributuion function of the input data $ f_x(x) $ we can use a training set
			\begin{equation}
				T = {x_1,\ldots,x_N}
			\end{equation},
			where $N$ should be considerably larger than the codebook size $ K $,$  N \le 500K $ for this work.
			
			The algorithm can then be defined as:
			\begin{enumerate}
				\item initial codebook
				\item optimal partition
				\item new codebook
				\item distortion
				\item terminate?
			\end{enumerate}
		
		\subsection{Split approach}
				This approach is based on starting a codebook as 
				\begin{equation}
					\{(1-\epsilon)y_{avg}, (1+\epsilon)y_{avg}\},
				\end{equation}
				where $ y_{avg} $ is the average of the vectors in the training set.
				The LBG algorithm is then applied to this codebook.
				The returning optimized codebook is split in the same way, i.e.
				\begin{equation}
					\{(1-\epsilon)y_i, (1+\epsilon)y_i, \ldots, (1-\epsilon)y_N, (1+\epsilon)y_N \}, 
				\end{equation}
				This implies that the codebook size will double in each iteration until we get the desired size K, $ N=2,4,8, \ldots,K $.			
		
	
	\section{Results}
		There were several tests made to fully understand the performance of this method.
		
		\subsection{Important Parameters}
			As required there are 4 scenrarios
			\begin{table}[H]
				\centering
				\begin{tabular}{c|c|c}
					\textbf{L} 		& \textbf{R} 	& \textbf{K} 	\\ \hline
					$ 2 $			& $ 2 $ 		& $ 16 $	  	\\ \hline
					$ 2 $			& $ 4 $ 	  	& $ 256 $ 		\\ \hline	
					$ 4 $			& $ 1 $ 		& $ 16 $ 		\\ \hline	
					$ 4 $			& $ 2 $			& $	256 $ 		\\
				\end{tabular}
				\caption{Scenarios}
				\label{table:Scenarios}
			\end{table}
		where K is the codebook size
		\begin{equation}
			K = 2^{RL}.
		\end{equation} 
		
		
		\subsection{Training Sets}
			There 3 different trainng sets used:
			\begin{itemize}
				\item All audio files from MC dataset
				\item Only the Say Nada song
				\item All Audio Files and All Popular Music
			\end{itemize}
				
			Each training set was limited in size. 
			For each file I extracted the middle part to result in the following relative size (N/K).
				
			\begin{table}[H]
				\centering
				\begin{tabular}{c|c|c}
					\textbf{Training set} & \textbf{N/K for L = 2} 	& \textbf{N/K for L = 4} \\ \hline
					All Audio 			& $ 1250 $ 					& $ 625 $	 			 \\ \hline
					Say Nada			& $ 1000 $ 				  	& $ 500 $ \\ \hline	
					All Music and Audio & $ 4844 $					& $	2422 $ \\
				\end{tabular}
				\caption{Relative Sizes of each Training Set}
				\label{table:TrainSets}
			\end{table}
			
			These sizes allowed fast enough codebook computation.
			Having training sets with and without including the encoding objects will benefit our comparison and possible conclusions.
				
		\subsection{Training Performance}
		
			The tests were made using $ \epsilon = 0.01 $.
			\begin{table}[H]
				\centering
				\begin{tabular}{c|c|c|c|c}
					\textbf{Training set} & \textbf{2,2} 			& \textbf{2,4}			&  \textbf{4,1}				& \textbf{4,2} \\ \hline
					All Audio 			& $ 1.51 \times 10^{5} $ 	& $ 3.53 \times 10^{5} $& $4.48 \times 10^{5} $ 	& $ 3.15 \times 10^{6} $ \\ \hline
					Music: Say Nada		& $ 4.36 \times 10^{6} $ 	& $ 3.71 \times 10^{6} $& $ 3.31 \times 10^{7} $  	& $ 2.70 \times 10^{7} $ \\ \hline
					All Music and Audio & $ 2.47 \times 10^{6} $	& $	1.93 \times 10^{6}$	& $ 9.70 \times 10^{6} $	& $	1.42 \times 10^{7} $ \\
				\end{tabular}
				\caption{Distortion for each training set and each values of L and R}
				\label{table:TrainDist}
			\end{table}
			
			\begin{table}[H]
				\centering
				\begin{tabular}{c|c|c|c|c}
					\textbf{Training set}	 	& \textbf{2,2} & \textbf{2,4}	& \textbf{4,1} & \textbf{4,2}\\ \hline
					All Audio 					& $ 1.29 s $ 	& $ 179.09 s $	& $ 0.45 s $ 	& $ 86.02 5 s $	\\ \hline
					Music: Say Nada				& $ 0.75 s $	& $ 114.41 s $	& $ 0.47 s $ 	& $ 55.81 s $	\\ \hline
					All Music and All Audio 	& $ 2.57 s $	& $	556.13 s $	& $ 1.21 s $	& $	266.74 s $	\\
				\end{tabular}
				\caption{Time for each training set and each values of L and R}
				\label{table:TrainTime}
			\end{table}
		
			We can see that (4,1) is clearly the fastest training.
			The training time is mostly dependent on the value K.
			The distortion is noticeably larger for L = 4.
			
		\subsection{Encoding Performance}
			In summary I got the following results:
			
			\begin{table}[H]
				\centering
				\begin{tabular}{c|c|c|c|c}
					\textbf{Encoded}	& \textbf{2,2} 	& \textbf{2,4}	& \textbf{4,1} & \textbf{4,2}\\ \hline
					70mono					& $ 1.45 s $ 	& $  s $	& $ 0.75 s $ 	& $  5 s $	\\ \hline
					Average Music			& $ 13.44 s $	& $  s $	& $ 6.78 s $ 	& $  s $	\\ \hline	
					Worst Case				& $ 18.02 s $	& $	 s $	& $ 8.24 s $	& $	 s $	\\ \hline
					Best Case				& $ 9.00 s $	& $	 s $	& $ 4.63 s $	& $	 s $	\\
				\end{tabular}
				\caption{Time for each encoding object and each values of L and R}
				\label{table:EncodeTime}
			\end{table}
			There is no noticeable difference between using the different training sets.
			
			\begin{table}[H]
				\centering
				\begin{tabular}{c|c|c|c|c}
					\textbf{Encoded} & \textbf{2,2} 			& \textbf{2,4}		&  \textbf{4,1}				& \textbf{4,2} \\ \hline
					70mono			& $ 2.5 \times 10^{5} $ 	& $  \times 10^{} $	& $6.10 \times 10^{5} $ 	& $  \times 10^{} $ \\ \hline
					Average Music	& $ 3.40 \times 10^{6} $ 	& $  \times 10^{} $& $ 4.38 \times 10^{6} $  	& $  \times 10^{} $ \\ \hline	
					Worst Case 		& $ 1.53 \times 10^{7} $	& $	 \times 10^{} $& $ 1.51 \times 10^{7} $		& $  \times 10^ $ \\ \hline
					Best Case 		& $ 3.66 \times 10^{5} $	& $  \times 10^{} $& $ 6.90 \times 10^{5} $ 	& $	 \times 10^ $ \\
				\end{tabular}
				\caption{Distortion for each encoding object and each values of L and R}
				\label{table:EncodeDist}
			\end{table}
		
			
			Encoding music files using All Audio as training se gives us in average 3 times the distortion when using Say Nada as the training set.
			When using Audio and Music as the training set we got half the distortion compared to using Say Nada.
			For (2,4) we get actually 11 times the distortion.
			
			
			\begin{table}[H]
				\centering
				\begin{tabular}{c|c|c|c|c}
					\textbf{Encoded} 	& \textbf{2,2} 	& \textbf{2,4}	& \textbf{4,1}	& \textbf{4,2} \\ \hline
					70mono				& $ 12.55 $ 	& $   $			& $ 10.10 $		& $  $ 		\\ \hline
					Average Music		& $ 13.83 $ 	& $   $			& $ 11.80 $  	& $  $ 		\\ \hline	
					Worst Case 			& $ 17.01 $		& $	  $			& $ 16.60 $		& $   $ 	\\ \hline
					Best Case 			& $ 8.74 $		& $   $			& $ 8.00 $ 		& $	  $ 	\\
				\end{tabular}
				\caption{SNR(dB) for each encoding object and each values of L and R}
				\label{table:EncodeSNR}
			\end{table}
		
		Regarding Signal to Noise Ratio (SNR) in dB, there are significant differences regarding the training set used.
		
		\begin{table}[H]
			\centering
			\begin{tabular}{c|c|c|c|c}
				\textbf{Encoded} 			& \textbf{2,2} 	& \textbf{2,4}	& \textbf{4,1}	& \textbf{4,2} \\ \hline
				All Audio 					& $ 10.35 $ 	& $ 20.31 $		& $ 9.66 $ 		& $ 17.25 $	\\ \hline
				Music: Say Nada				& $ 14.15 $		& $ 26.63 $		& $ 11.57 $ 	& $ 20.74 $	\\ \hline
				All Music and All Audio 	& $ 16.98 $		& $	27.06 $		& $ 14.17 $		& $	21.05 $	\\
			\end{tabular}
			\caption{Average SNR(dB) for each training set and each values of L and R}
			\label{table:EncodeSNRT}
		\end{table}
		
		
		\subsection{Training set including the encoding object...}
			
	
	\section{Conclusions}
	
		1 - Using music as a training set is clearly superior when we will use the codebook to encode music files.
			Vice-versa is also valid, although less significantly. Encoding 70mono using All audio as training set produces in average half the distortion.
		
		2 - 
		
		3 - 
		
		4 - 
		
		
		
		
		
		
\end{document}



