\documentclass[a4paper, 11pt]{article}
\usepackage{geometry}
\usepackage{indentfirst}
\usepackage{setspace}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{caption}
\usepackage{indentfirst}
\setlength{\parindent}{20pt}
\usepackage{amssymb}
\usepackage{float}

\graphicspath{ {./images/} }
\geometry{left=2.5cm, right=2.5cm, top=2.5cm, bottom=2.5cm}

\begin{document}	
	\title{Project \# 3. Multimedia Coding }
	\author{{\small Alexandre Rodrigues (2039952)}}
	\date{\today}
	\maketitle
	
	\section{Introduction}
		This report is dedicated to explain the usage of the LBG-split algorithm and how to implement it.
		The Linde-Buzo-Gray algorithm is a lossy coding technique that uses vector quantization, meaning that a block of input samples is processed together.
		We will understand what affects the final signal to noise ratio: codevector length L, rate R, training set used, etc..
	
	\section{Technical Approach}
		Each vector of size L samples can be defined as
		\begin{equation}
			x = [x_1, x_2, \ldots, x_L], x \in R^L
		\end{equation}
		where $x_i, i=1,2,\ldots,L$ are input samples. 
		Using $y_i $ as a codevector, 
		\begin{equation}
			B =  \{y_1, y_2, \ldots, y_L\}
		\end{equation} 
		is the set of reconstruction levels, i.e. the codebook, of size K.
		The decision cells will be
		\begin{equation}
			I_i \in R^L, i = 1, 2, \ldots, K, such that I_i intersect I_j = 0 \aleph i \neq j and union k i=1 I_i = R^L
		\end{equation} 
		
		The quantization procedure aims to minimize the distortion D, defined as 
		\begin{equation}
			D = E [||x-Q(x)||^2],
		\end{equation} 
		where $ Q(x) = y_i $ maps the input vector $ x $ to $y_i \in B$ when $x \in I_i $.
		The bitrate $R$ is the number of bits used to quantize each component of the codevector
		\begin{equation}
			R = \frac{1}{L}log_2K,
			\label{eq:rate}
		\end{equation} 
		where K is the codebook size, in this case a power of 2.
			
		\subsection{LBG}
			Since we do not know the probability distribution function of the input data $ f_x(x) $ we can use a training set
			\begin{equation}
				T = {x_1,\ldots,x_N}
			\end{equation},
			where $N$ should be considerably larger than the codebook size $ K $,$  N \le 500K $ for this work.
			
			The algorithm can then be defined as:
			\begin{enumerate}
				\item initial codebook
				\item optimal partition
				\item new codebook
				\item distortion
				\item terminate?
			\end{enumerate}
		
		\subsection{Split approach}
				This approach is based on starting a codebook as 
				\begin{equation}
					\{(1-\epsilon)y_{avg}, (1+\epsilon)y_{avg}\},
				\end{equation}
				where $ y_{avg} $ is the average of the vectors in the training set.
				The LBG algorithm is then applied to this codebook.
				The returning optimized codebook is split in the same way, i.e.
				\begin{equation}
					\{(1-\epsilon)y_i, (1+\epsilon)y_i, \ldots, (1-\epsilon)y_N, (1+\epsilon)y_N \}, 
				\end{equation}
				This implies that the codebook size will double in each iteration until we get the desired size K, $ N=2,4,8, \ldots,K $.			
		
	
	\section{Results}
		There were several tests made to fully understand the performance of this method.
		
		\subsection{Important Parameters}
			As required there are 4 scenrarios
			\begin{table}[H]
				\centering
				\begin{tabular}{c|c|c}
					\textbf{L} 		& \textbf{R} 	& \textbf{K} 	\\ \hline
					$ 2 $			& $ 2 $ 		& $ 16 $	  	\\ \hline
					$ 2 $			& $ 4 $ 	  	& $ 256 $ 		\\ \hline	
					$ 4 $			& $ 1 $ 		& $ 16 $ 		\\ \hline	
					$ 4 $			& $ 2 $			& $	256 $ 		\\
				\end{tabular}
				\caption{Scenarios}
				\label{table:Scenarios}
			\end{table}
			where K is the codebook size, from equation \ref{eq:rate},
			\begin{equation}
				K = 2^{RL}.
			\end{equation} 
		
		
		\subsection{Training Sets}
			There 3 different trainng sets used:
			\begin{itemize}
				\item All audio files from MC dataset
				\item Only the Say Nada song
				\item All Audio Files and All Popular Music
			\end{itemize}
				
			Each training set was limited in size. 
			For each file I extracted the middle part to result in the following relative size (N/K).
				
			\begin{table}[H]
				\centering
				\begin{tabular}{c|c|c}
					\textbf{Training set} & \textbf{N/K for L = 2} 	& \textbf{N/K for L = 4} \\ \hline
					All Audio 			& $ 1250 $ 					& $ 625 $	 			 \\ \hline
					Say Nada			& $ 1000 $ 				  	& $ 500 $ \\ \hline	
					All Music and Audio & $ 4844 $					& $	2422 $ \\
				\end{tabular}
				\caption{Relative Sizes of each Training Set}
				\label{table:TrainSets}
			\end{table}
			
			These sizes allowed fast enough codebook computation.
			Having training sets with and without including the encoding objects will benefit our comparison and possible conclusions.
				
		\subsection{Training Performance}
		
			The tests were made using $ \epsilon = 0.01 $.
			\begin{table}[H]
				\centering
				\begin{tabular}{c|c|c|c|c}
					\textbf{Training set} & \textbf{2,2} 			& \textbf{2,4}			&  \textbf{4,1}				& \textbf{4,2} \\ \hline
					All Audio 			& $ 1.51 \times 10^{5} $ 	& $ 3.53 \times 10^{5} $& $4.48 \times 10^{5} $ 	& $ 3.15 \times 10^{6} $ \\ \hline
					Music: Say Nada		& $ 4.36 \times 10^{6} $ 	& $ 3.71 \times 10^{6} $& $ 3.31 \times 10^{7} $  	& $ 2.70 \times 10^{7} $ \\ \hline
					All Music and Audio & $ 2.47 \times 10^{6} $	& $	1.93 \times 10^{6}$	& $ 9.70 \times 10^{6} $	& $	1.42 \times 10^{7} $ \\
				\end{tabular}
				\caption{Distortion for each training set and each values of L and R}
				\label{table:TrainDist}
			\end{table}
			
			\begin{table}[H]
				\centering
				\begin{tabular}{c|c|c|c|c}
					\textbf{Training set}	 	& \textbf{2,2} & \textbf{2,4}	& \textbf{4,1} & \textbf{4,2}\\ \hline
					All Audio 					& $ 1.29 s $ 	& $ 179.09 s $	& $ 0.45 s $ 	& $ 86.02 5 s $	\\ \hline
					Music: Say Nada				& $ 0.75 s $	& $ 114.41 s $	& $ 0.47 s $ 	& $ 55.81 s $	\\ \hline
					All Music and All Audio 	& $ 2.57 s $	& $	556.13 s $	& $ 1.21 s $	& $	266.74 s $	\\
				\end{tabular}
				\caption{Time for each training set and each values of L and R}
				\label{table:TrainTime}
			\end{table}
		
			We can see that (4,1) is clearly the fastest training.
			The training time is mostly dependent on the value K.
			The distortion is noticeably larger for L = 4.
			
		\subsection{Encoding Performance}
			We will discuss performance regarding a music file form the DataSet (70mono.wav), various popular musics and a speech file from the DataSet (49mono.wav).
			In summary I got the following results:
			
			\begin{table}[H]
				\centering
				\begin{tabular}{c|c|c|c|c}
					\textbf{Encoded}	& \textbf{2,2} 	& \textbf{2,4}	& \textbf{4,1} & \textbf{4,2}\\ \hline
					Audio 70				& $ 1.50 s $ 	& $ 17.81 s $	& $ 0.74 s $ 	& $ 10.24 s $	\\ \hline
					Average Music			& $ 13.44 s $	& $ 188.31 s $	& $ 6.78 s $ 	& $ 95.41 s $	\\ \hline	
					Worst Case				& $ 18.02 s $	& $	137.08 s $	& $ 8.24 s $	& $	118.51 s $	\\ \hline
					Best Case				& $ 9.00 s $	& $	253.91 s $	& $ 4.63 s $	& $	70.26 s $	\\ \hline
					Audio 49				& $ 1.38 s $	& $	18.78 s $	& $ 0.79 s $	& $	9.73 s $	\\
				\end{tabular}
				\caption{Time for each encoding object and each values of L and R}
				\label{table:EncodeTime}
			\end{table}
			There is no noticeable difference between using the different training sets.
			The music files clearly take more time to encode, this can be mostly due to the duration of the audio clip being larger.
			Both speech and music audio files from the dataset have similar encoding time due to their reduced duration.
			
			\begin{table}[H]
				\centering
				\begin{tabular}{c|c|c|c|c}
					\textbf{Encoded} & \textbf{2,2} 			& \textbf{2,4}		&  \textbf{4,1}				& \textbf{4,2} \\ \hline
					70mono			& $ 2.94 \times 10^{5} $ 	& $ 2.81 \times 10^{4} $& $ 6.32 \times 10^{5} $ 	& $ 7.51 \times 10^{4} $ \\ \hline
					Average Music	& $ 3.40 \times 10^{6} $ 	& $ 3.35 \times 10^{5} $& $ 4.38 \times 10^{6} $  	& $ 7.30 \times 10^{5} $ \\ \hline	
					Worst Case 		& $ 1.53 \times 10^{7} $	& $	1.95 \times 10^{6} $& $ 1.51 \times 10^{7} $	& $ 2.85 \times 10^6 $ \\ \hline
					Best Case 		& $ 3.66 \times 10^{5} $	& $ 2.21 \times 10^{4} $& $ 6.90 \times 10^{5} $ 	& $	1.99 \times 10^5 $ \\ \hline
					Audio 49		& $ 3.42 \times 10^{5} $	& $ 3.48 \times 10^{4} $& $ 7.61 \times 10^{5} $ 	& $ 1.10 \times 10^{5} $	\\
				\end{tabular}
				\caption{Distortion for each encoding object and each values of L and R}
				\label{table:EncodeDist}
			\end{table}		
			Distortion is larger for the music files which can also be due to their larger duration.		
			
			\begin{table}[H]
				\centering
				\begin{tabular}{c|c|c|c|c}
					\textbf{Encoded} 	& \textbf{2,2} 	& \textbf{2,4}	& \textbf{4,1}	& \textbf{4,2} \\ \hline
					Audio 70			& $ 12.55 $ 	& $  23.17 $	& $ 10.10 $		& $ 18.33 $ 	\\ \hline
					Average Music		& $ 13.83 $ 	& $  24.67  $	& $ 11.80 $  	& $ 19.68 $ 	\\ \hline	
					Worst Case 			& $ 8.74 $		& $	 17.54 $	& $ 8.00 $		& $ 15.15  $ 	\\ \hline
					Best Case 			& $ 17.01 $		& $ 27.86 $		& $ 16.60 $ 	& $	22.99  $ 	\\ \hline
					Audio 49 			& $ 11.69 $		& $ 21.87  $	& $ 8.58 $ 		& $	16.64  $ 	\\
				\end{tabular}
				\caption{SNR(dB) for each encoding object and each values of L and R}
				\label{table:EncodeSNR}
			\end{table}
		
		Regarding Signal to Noise Ratio (SNR) in dB, there are significant differences regarding the training set used.
		
		\begin{table}[H]
			\centering
			\begin{tabular}{c|c|c|c|c}
				\textbf{Encoded} 			& \textbf{2,2} 	& \textbf{2,4}	& \textbf{4,1}	& \textbf{4,2} \\ \hline
				All Audio 					& $ 11.26 $ 	& $ 21.45 $		& $ 10.24 $ 	& $ 17.79 $	\\ \hline
				Music: Say Nada				& $ 13.22 $		& $ 25.01 $		& $ 10.21 $ 	& $ 19.57 $	\\ \hline
				All Music and All Audio 	& $ 15.86 $		& $	26.11 $		& $ 13.31 $		& $	20.22 $	\\
			\end{tabular}
			\caption{Average SNR(dB) for each training set and each values of L and R}
			\label{table:EncodeSNRT}
		\end{table}
		
		The All Audio training set is clearly superior in SNR.
		
		\subsection{Choosing a Training Set}
			\begin{enumerate}
				\item Training Time: Mostly dependent on the amount of data we get the training set from, best: AllAudio.
				\item Training Distortion: $ D_{SayN} \approxeq 2 D_{A+M} \approxeq 5 D_{Audio} $.
				\item Encoding Time: No significant differences
				\item Encoding Distortion: $  D_{Audio} > D_{SayNada} > D_{A+M} $
				\item Final SNR: $  SNR_{A+M} < SNR_{SayNada} < SNR_{Audio} $
			\end{enumerate}
			
			We can although disregard training time due to being a one time only computation.
			For a fast usage we would choose the All Audio training set.
			To have the best SNR the clear choice is the biggest training set, i.e. the Audio and Music training set.
			
	
	\section{Conclusions}
		\begin{itemize}
			\item Using music as a training set is clearly superior when we will use the codebook to encode music files. Vice-versa is also valid, although less significantly. Encoding 70mono using All audio as training set produces in average half the distortion.
			\item The best scenario and training set combination regarding SNR is L=2, R=2, All Audio and Music. This combination is also the slowest to encode.
			\item Encoding Time is proportional to the rate R and the audio file duration.
			\item Final SNR depends on the codebook size K but has a negative effect when increasing the codevector length L. The rule of thumb $D \approx 6R$ applies when $ L =2 $. For$  L=4 $, $ SNR_{R=1} = 11.25 > 6 $ and $ SNR_{R=2} = 19.19 > 12 $.
		\end{itemize}	
		
		
\end{document}



